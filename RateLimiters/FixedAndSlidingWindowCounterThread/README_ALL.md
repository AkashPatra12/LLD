
# ğŸš¦ Python Rate Limiter

This project demonstrates **five rate limiting algorithms** in Python to control client request rates, useful for API protection, login throttling, and infrastructure traffic shaping.

Supported algorithms:
- âœ… Fixed Window Counter
- âœ… Sliding Window Log
- âœ… Sliding Window Counter
- âœ… Leaky Bucket
- âœ… Token Bucket

It uses a unified interface and supports multithreaded request simulation.

---

## ğŸ§  Algorithm Details with Visuals

### 1. â²ï¸ Fixed Window Counter
**Logic**: Count requests in a fixed-sized time bucket (e.g., 5 seconds).

```
Time:   0s    5s   10s   15s   20s
        |-----|-----|-----|-----|
Client:  â— â— â— â— â—         â— â— â— â— â—
         (limit hit)       (limit hit)
```

- âœ… **Pros**: Fast, easy to implement  
- âŒ **Cons**: Allows burst at boundary of time windows

---

### 2. ğŸ“œ Sliding Window Log
**Logic**: Maintain a deque of timestamps and remove outdated entries continuously.

```
Sliding window moves forward:

0s----10s----20s----30s----40s----50s----60s----70s
      |-----------Sliding Window-----------|
      âœ…    âœ…                     âœ…
                               New âœ…  New âœ…
                                     New âŒ (limit exceeded)
```

- âœ… **Pros**: Highly accurate  
- âŒ **Cons**: Memory-intensive for high-frequency clients

---

### 3. ğŸ“Š Sliding Window Counter
**Logic**: Divide total window into equal-length buckets and sum request counts.

```
Buckets:
| 12:00 | 12:01 | 12:02 | 12:03 | 12:04 |
|   2   |   1   |   0   |   3   |   2   |
           <--- Sliding Window --->
Total = 6 requests in the last 3 buckets
```

- âœ… **Pros**: Space-efficient, good accuracy  
- âŒ **Cons**: Slightly approximate due to time binning

---

### 4. ğŸ’§ Leaky Bucket
**Logic**: Requests enter a queue that leaks at a steady rate.

```
Rate: 1 req/sec | Capacity: 5

Time âœ   [0s][1s][2s][3s][4s][5s][6s][7s]
Input âœ   âœ…  âœ…  âœ…  âœ…  âœ…  âŒ  âœ…  âœ…
Bucket âœ [â–“â–“â–“â–“â–“] Leaks â–½ â–½ â–½ â–½ â–½ âœ [â–“â–“]
```

- âœ… **Pros**: Smooths spikes into steady flow  
- âŒ **Cons**: Not suitable for bursty traffic

---

### 5. ğŸª™ Token Bucket
**Logic**: Bucket refills tokens at a steady rate; requests consume tokens.

```
Rate: 1 token/sec | Capacity: 5

Time âœ  0s   1s   2s   3s   4s   5s
Tokens: ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™
Reqs:   âœ… âœ… âœ… âœ… âœ… âŒ (no tokens left)
       [tokens consumed]
```

- âœ… **Pros**: Allows bursts + recovers over time  
- âŒ **Cons**: Requires precise token refill logic

---

## ğŸ“Š Time & Space Complexity

| Algorithm              | Time Complexity | Space per Client |
|------------------------|------------------|------------------|
| Fixed Window           | O(1)             | O(1)             |
| Sliding Window Log     | O(1) â€“ O(n)      | O(n)             |
| Sliding Window Counter | O(1) â€“ O(k)      | O(k)             |
| Leaky Bucket           | O(1)             | O(1)             |
| Token Bucket           | O(1)             | O(1)             |

> `n` = number of requests per window  
> `k` = number of sub-windows

---

## ğŸ§° Use-Case Recommendations

| Use Case                       | Recommended Limiter       | Why                                       |
|--------------------------------|----------------------------|-------------------------------------------|
| API throttling with bursts     | Token Bucket               | Burst-tolerant, smooth refill             |
| Login rate limit               | Sliding Window Log         | Timestamp precision prevents abuse        |
| Real-time message flow         | Leaky Bucket               | Drips traffic evenly                      |
| Basic request limiting         | Fixed Window               | Simple and effective                      |
| Performance + precision blend  | Sliding Window Counter     | Balanced overhead and accuracy            |

---

## ğŸŒ Distributed System Scaling

### ğŸ§± 1. Centralized Data Store (Redis)
- Store rate limit state per client
- Use Redis commands: `INCR`, `EXPIRE`, `ZADD`, etc.
- âœ… Pros: Fast, atomic  
- âŒ Cons: Centralized point of failure

### ğŸ“¦ 2. Local + Periodic Sync
- Maintain local limits per node
- Sync with central store periodically

### âš–ï¸ 3. Sharded Clients
- Hash client IDs across limiter servers or Redis partitions

### ğŸŒ 4. CDN / Edge-Based Limiting
- Rate limit at edge nodes (e.g. Cloudflare)

---

## ğŸš€ How to Run

```bash
python rate_limiter.py
```

### Output:
```
Fixed Rate Limiter with Threads:
Client: client_fixed_0, Allowed: True
Client: client_fixed_0, Allowed: False
...

Token Bucket Rate Limiter with Threads:
Client: client_token_1, Allowed: True
...
```

---

## ğŸ“ Project Structure

- `RateLimiter`: Abstract interface
- `FixedWindowRateLimiter`
- `SlidingWindowRateLimiter`
- `SlidingWindowCounterRateLimiter`
- `LeakyBucketRateLimiter`
- `TokenBucketRateLimiter`
- `RateLimiterFactory`: Centralized creator
- `simulate_requests()`: Multithreaded test runner
- `main`: Demonstrates each limiter with multiple clients

---

## ğŸ”® Future Enhancements

- [ ] Redis integration (centralized store)
- [ ] Flask / FastAPI REST wrapper
- [ ] Prometheus / Grafana observability
- [ ] Configurable YAML-based policies
- [ ] Async / AIO support

---

## ğŸ“œ License

MIT â€” Use freely in production, testing, or education.
